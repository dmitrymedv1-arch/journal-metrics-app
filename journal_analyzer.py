# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: ~615
# –ò–∑–º–µ–Ω–µ–Ω–∏—è:
# +30 —Å—Ç—Ä–æ–∫: –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ calculate_metrics_dynamic –¥–ª—è –¥–≤—É—Ö CiteScore –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–∞—Ç—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–∏

import requests
import pandas as pd
import numpy as np
from datetime import datetime, date, timedelta
import time
import calendar
from collections import defaultdict
import pickle
import hashlib
import os
import warnings
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from functools import partial
warnings.filterwarnings('ignore')

base_url_crossref = "https://api.crossref.org/works"
base_url_openalex = "https://api.openalex.org/works"
CACHE_DIR = "journal_analysis_cache"
CACHE_DURATION = timedelta(hours=24)

def validate_issn(issn):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ ISSN"""
    if not issn:
        return False
    pattern = r'^\d{4}-\d{3}[\dXx]$'
    return re.match(pattern, issn) is not None

def ensure_cache_dir():
    """–°–æ–∑–¥–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∫—ç—à–∞ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç"""
    if not os.path.exists(CACHE_DIR):
        os.makedirs(CACHE_DIR)

def get_cache_key(*args):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –∫—ç—à–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤"""
    key_string = "_".join(str(arg) for arg in args)
    return hashlib.md5(key_string.encode()).hexdigest()

def save_to_cache(data, cache_key):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à"""
    ensure_cache_dir()
    cache_file = os.path.join(CACHE_DIR, f"{cache_key}.pkl")
    cache_data = {
        'data': data,
        'timestamp': datetime.now()
    }
    with open(cache_file, 'wb') as f:
        pickle.dump(cache_data, f)

def load_from_cache(cache_key):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞"""
    cache_file = os.path.join(CACHE_DIR, f"{cache_key}.pkl")
    if not os.path.exists(cache_file):
        return None
    try:
        with open(cache_file, 'rb') as f:
            cache_data = pickle.load(f)
        if datetime.now() - cache_data['timestamp'] < CACHE_DURATION:
            print(f"–ó–∞–≥—Ä—É–∂–µ–Ω –∫—ç—à –¥–ª—è –∫–ª—é—á–∞: {cache_key}")
            return cache_data['data']
        else:
            os.remove(cache_file)
            return None
    except:
        return None

def get_journal_name_from_issn(issn, use_cache=True):
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∂—É—Ä–Ω–∞–ª–∞ –ø–æ ISSN:
    1. –°–Ω–∞—á–∞–ª–∞ —á–µ—Ä–µ–∑ Crossref API
    2. –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ - —á–µ—Ä–µ–∑ OpenAlex API
    3. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç fallback –Ω–∞–∑–≤–∞–Ω–∏–µ
    """
    if not validate_issn(issn):
        return f"–ñ—É—Ä–Ω–∞–ª ISSN {issn}"
    
    cache_key = get_cache_key("journal_name", issn)
    if use_cache:
        cached_name = load_from_cache(cache_key)
        if cached_name:
            print(f"–ù–∞–∑–≤–∞–Ω–∏–µ –∂—É—Ä–Ω–∞–ª–∞ –∏–∑ –∫—ç—à–∞: {cached_name}")
            return cached_name
    
    # 1. –ü–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ Crossref
    try:
        print(f"üîç –ü–æ–∏—Å–∫ –∂—É—Ä–Ω–∞–ª–∞ —á–µ—Ä–µ–∑ Crossref: {issn}")
        params = {
            'filter': f'issn:{issn}',
            'rows': 1,
            'mailto': 'example@example.com'
        }
        response = requests.get(base_url_crossref, params=params, timeout=30)
        response.raise_for_status()
        data = response.json()
        
        if data['message']['total-results'] > 0:
            journal_name = data['message']['items'][0].get('container-title', [f"–ñ—É—Ä–Ω–∞–ª ISSN {issn}"])[0]
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —á–µ—Ä–µ–∑ Crossref: {journal_name}")
            save_to_cache(journal_name, cache_key)
            return journal_name
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ Crossref –¥–ª—è {issn}: {e}")
    
    # 2. –ü–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ OpenAlex
    try:
        print(f"üîç –ü–æ–∏—Å–∫ –∂—É—Ä–Ω–∞–ª–∞ —á–µ—Ä–µ–∑ OpenAlex: {issn}")
        url = f"https://api.openalex.org/journals?filter=issn:{issn}&per-page=1"
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        data = response.json()
        
        if data['results']:
            journal_name = data['results'][0].get('display_name', f"–ñ—É—Ä–Ω–∞–ª ISSN {issn}")
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —á–µ—Ä–µ–∑ OpenAlex: {journal_name}")
            save_to_cache(journal_name, cache_key)
            return journal_name
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ OpenAlex –¥–ª—è {issn}: {e}")
    
    # 3. Fallback
    fallback_name = f"–ñ—É—Ä–Ω–∞–ª ISSN {issn}"
    print(f"‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback –Ω–∞–∑–≤–∞–Ω–∏–µ: {fallback_name}")
    save_to_cache(fallback_name, cache_key)
    return fallback_name

def parallel_fetch_citations_openalex(dois_list, citation_start_date, citation_end_date, max_workers=20, progress_callback=None):
    """
    –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û–ï –ø–æ–ª—É—á–µ–Ω–∏–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π —á–µ—Ä–µ–∑ OpenAlex —Å ThreadPoolExecutor
    –£—Å–∫–æ—Ä–µ–Ω–∏–µ –¥–æ 5x –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
    """
    results = {}
    total_dois = len(dois_list)
    processed = 0
    
    def fetch_single_citation(doi):
        """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ DOI"""
        return fetch_citations_openalex(
            doi, 
            citation_start_date, 
            citation_end_date,
            update_progress=None
        )
    
    print(f"üöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ {total_dois} DOI ({max_workers} –ø–æ—Ç–æ–∫–æ–≤)")
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_doi = {
            executor.submit(fetch_single_citation, doi): doi 
            for doi in dois_list
        }
        
        for future in as_completed(future_to_doi):
            doi = future_to_doi[future]
            try:
                result = future.result(timeout=120)
                results[doi] = result
                processed += 1
                
                if progress_callback and processed % 10 == 0:
                    progress = min(1.0, processed / total_dois)
                    progress_callback(progress)
                
                print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω DOI {processed}/{total_dois}: {doi[:20]}...")
                
            except Exception as exc:
                print(f"‚ùå –û—à–∏–±–∫–∞ –¥–ª—è DOI {doi}: {exc}")
                results[doi] = {
                    'doi': doi,
                    'count': 0,
                    'total_count': 0,
                    'all_citations': [],
                    'publication_year': None
                }
    
    if progress_callback:
        progress_callback(1.0)
    
    print(f"üéâ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(results)}/{total_dois} DOI")
    return results

def validate_parallel_openalex(max_workers=20):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ OpenAlex"""
    try:
        response = requests.get(f"{base_url_openalex}?per-page=1", timeout=10)
        response.raise_for_status()
        
        if max_workers > 50:
            print("‚ö†Ô∏è max_workers –æ–≥—Ä–∞–Ω–∏—á–µ–Ω 50 –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏")
            return False, 50
        
        return True, max_workers
        
    except Exception as e:
        print(f"‚ùå OpenAlex –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏–∏: {e}")
        return False, 1

def fetch_articles_enhanced(issn, from_date, until_date, use_cache=True, progress_callback=None):
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–µ–π —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π —á–µ—Ä–µ–∑ Crossref"""
    if not validate_issn(issn):
        print(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç ISSN: {issn}")
        return []

    cache_key = get_cache_key("fetch_articles_enhanced", issn, from_date, until_date)
    if use_cache:
        cached_data = load_from_cache(cache_key)
        if cached_data is not None:
            return cached_data

    items = []
    cursor = "*"
    excluded_types = {
        'editorial', 'letter', 'correction', 'retraction',
        'book-review', 'news', 'announcement', 'abstract'
    }

    total_pages = 10
    current_page = 0

    while True:
        params = {
            'filter': f'issn:{issn},from-pub-date:{from_date},until-pub-date:{until_date}',
            'rows': 1000,
            'cursor': cursor,
            'mailto': 'example@example.com'
        }
        try:
            print(f"fetch_articles_enhanced: –ó–∞–ø—Ä–æ—Å —Å—Ç—Ä–∞–Ω–∏—Ü—ã {current_page + 1} –¥–ª—è ISSN {issn} ({from_date}‚Äì{until_date})")
            resp = requests.get(base_url_crossref, params=params, timeout=60)
            resp.raise_for_status()
            data = resp.json()
            message = data['message']
            filtered_items = []
            for item in message['items']:
                item_type = item.get('type', '').lower()
                print(f"–¢–∏–ø —Å—Ç–∞—Ç—å–∏: {item_type}, DOI: {item.get('DOI', 'N/A')}")
                if item_type not in excluded_types:
                    filtered_items.append(item)
            items.extend(filtered_items)
            print(f"fetch_articles_enhanced: –ü–æ–ª—É—á–µ–Ω–æ {len(filtered_items)} —Å—Ç–∞—Ç–µ–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {current_page + 1}")
            cursor = message.get('next-cursor')
            current_page += 1
            if progress_callback:
                progress = min(0.3 * current_page / total_pages, 0.3)
                progress_callback(progress)
            if not cursor or len(message['items']) == 0:
                print(f"fetch_articles_enhanced: –ó–∞–≤–µ—Ä—à–µ–Ω–æ, –≤—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {len(items)} —Å—Ç–∞—Ç–µ–π")
                break
            time.sleep(0.5)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≤ fetch_articles_enhanced –¥–ª—è ISSN {issn}: {e}")
            break

    if use_cache and items:
        save_to_cache(items, cache_key)
    return items

def fetch_citations_openalex(doi, citation_start_date, citation_end_date, update_progress=None):
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Ü–∏—Ç–∏—Ä—É—é—â–∏–µ —Ä–∞–±–æ—Ç—ã —á–µ—Ä–µ–∑ OpenAlex API —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –ø–µ—Ä–∏–æ–¥—É.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º –ø–µ—Ä–∏–æ–¥–µ –∏ –æ–±—â–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º.
    """
    cache_key = get_cache_key("fetch_citations_openalex", doi, citation_start_date, citation_end_date)
    cached_data = load_from_cache(cache_key)
    if cached_data is not None:
        return cached_data

    doi = doi.strip().replace('https://doi.org/', '') if doi.startswith('https://doi.org/') else doi.strip()
    work_url = f"{base_url_openalex}?filter=doi:{doi}"
    
    try:
        response = requests.get(work_url, timeout=30)
        response.raise_for_status()
        data = response.json()
        results = data.get('results', [])
        if not results:
            print(f"DOI {doi}: –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤ OpenAlex")
            save_to_cache({'doi': doi, 'count': 0, 'total_count': 0, 'all_citations': [], 'publication_year': None}, cache_key)
            return {'doi': doi, 'count': 0, 'total_count': 0, 'all_citations': [], 'publication_year': None}
        
        work_data = results[0]
        original_title = work_data.get('title', '–ù–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è')
        publication_year = work_data.get('publication_year', None)
        print(f"DOI {doi}: –ù–∞–π–¥–µ–Ω–∞ —Ä–∞–±–æ—Ç–∞ '{original_title[:50]}...', –ì–æ–¥: {publication_year}")
        
        work_id = work_data['id']
        work_openalex_id = work_id.split('/')[-1]
        cited_by_count = work_data.get('cited_by_count', 0)
        print(f"DOI {doi}: –û–±—â–µ–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π (OpenAlex): {cited_by_count}")
        
        citing_works = []
        page = 1
        next_cursor = None
        total_processed = 0
        
        while True:
            url = f"{base_url_openalex}?filter=cites:{work_openalex_id}&per-page=200"
            if next_cursor:
                url += f"&cursor={next_cursor}"
            try:
                response = requests.get(url, timeout=60)
                response.raise_for_status()
                data = response.json()
                results_count = len(data.get('results', []))
                print(f"DOI {doi}: –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}, –Ω–∞–π–¥–µ–Ω–æ {results_count} —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π")
                
                for work in data['results']:
                    citing_doi = work.get('doi', '').replace('https://doi.org/', '') if work.get('doi') else '–ù–µ—Ç DOI'
                    citing_title = work.get('title', '–ù–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è')
                    publication_date_str = work.get('publication_date', '–ù–µ—Ç –¥–∞—Ç—ã')
                    if publication_date_str != '–ù–µ—Ç –¥–∞—Ç—ã':
                        try:
                            pub_date = datetime.strptime(publication_date_str, '%Y-%m-%d').date()
                            if citation_start_date <= pub_date <= citation_end_date:
                                citing_works.append({
                                    'DOI': citing_doi,
                                    '–ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏': citing_title,
                                    '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': publication_date_str
                                })
                        except ValueError:
                            pass
                    total_processed += 1
                
                next_cursor = data.get('meta', {}).get('next_cursor')
                if not next_cursor:
                    print(f"DOI {doi}: –î–æ—Å—Ç–∏–≥–Ω—É—Ç –∫–æ–Ω–µ—Ü —Å–ø–∏—Å–∫–∞")
                    break
                
                page += 1
                if update_progress and cited_by_count > 0:
                    progress = min(1.0, total_processed / cited_by_count)
                    update_progress(progress)
                time.sleep(0.1)
                
            except requests.exceptions.RequestException as e:
                print(f"DOI {doi}: –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {e}")
                break
            except Exception as e:
                print(f"DOI {doi}: –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {e}")
                break
        
        count_period = len(citing_works)
        print(f"DOI {doi}: –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –≤ –ø–µ—Ä–∏–æ–¥–µ {citation_start_date}‚Äì{citation_end_date}: {count_period} –∏–∑ {cited_by_count}")
        result = {
            'doi': doi,
            'count': count_period,
            'total_count': cited_by_count,
            'all_citations': citing_works,
            'publication_year': publication_year
        }
        save_to_cache(result, cache_key)
        return result
        
    except requests.exceptions.RequestException as e:
        print(f"DOI {doi}: –û—à–∏–±–∫–∞ OpenAlex API: {e}")
        return {'doi': doi, 'count': 0, 'total_count': 0, 'all_citations': [], 'publication_year': None}
    except Exception as e:
        print(f"DOI {doi}: –û–±—â–∞—è –æ—à–∏–±–∫–∞: {e}")
        return {'doi': doi, 'count': 0, 'total_count': 0, 'all_citations': [], 'publication_year': None}

def get_seasonal_coefficients(journal_field="general"):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∑–≤–µ—à–µ–Ω–Ω—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
    seasonal_patterns = {
        "natural_sciences": {
            1: 0.85, 2: 1.05, 3: 1.25, 4: 1.15, 5: 1.00, 6: 0.95,
            7: 0.70, 8: 0.75, 9: 1.30, 10: 1.20, 11: 1.15, 12: 0.65
        },
        "general": {
            1: 0.90, 2: 1.15, 3: 1.20, 4: 1.15, 5: 1.00, 6: 1.00,
            7: 0.70, 8: 0.80, 9: 1.20, 10: 1.25, 11: 1.15, 12: 0.60
        }
    }
    return seasonal_patterns.get(journal_field, seasonal_patterns["general"])

def calculate_weighted_multiplier(current_date, seasonal_coefficients, method="balanced"):
    """–†–∞—Å—á–µ—Ç –≤–∑–≤–µ—à–µ–Ω–Ω–æ–≥–æ –º–Ω–æ–∂–∏—Ç–µ–ª—è"""
    current_year = current_date.year
    current_month = current_date.month
    days_passed = (current_date - date(current_year, 1, 1)).days + 1

    weighted_passed = 0
    for month in range(1, current_month + 1):
        _, month_days = calendar.monthrange(current_year, month)
        if month == current_month:
            month_days = current_date.day
        weighted_passed += seasonal_coefficients[month] * month_days

    total_weighted_year = sum(
        seasonal_coefficients[month] * calendar.monthrange(current_year, month)[1]
        for month in range(1, 13)
    )

    base_multiplier = total_weighted_year / weighted_passed if weighted_passed > 0 else 1.0

    if method == "conservative":
        return max(1.0, base_multiplier * 0.9)
    elif method == "optimistic":
        return max(1.0, base_multiplier * 1.1)
    else:
        return max(1.0, base_multiplier)

def detect_journal_field(issn, journal_name):
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±–ª–∞—Å—Ç–∏ –∂—É—Ä–Ω–∞–ª–∞"""
    field_keywords = {
        "natural_sciences": ['nature', 'science', 'physical', 'chemistry', 'physics'],
        "general": ['general', 'techno', 'acta']
    }
    journal_name_lower = journal_name.lower()
    for field, keywords in field_keywords.items():
        for keyword in keywords:
            if keyword in journal_name_lower:
                return field
    return "general"

def calculate_metrics_fast(issn, journal_name="–ù–µ —É–∫–∞–∑–∞–Ω–æ", use_cache=True):
    """–ë–´–°–¢–†–ê–Ø —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫ —á–µ—Ä–µ–∑ Crossref"""
    try:
        current_date = date.today()
        current_year = current_date.year
        journal_field = detect_journal_field(issn, journal_name)

        if_publication_years = [current_year - 2, current_year - 1]
        cs_publication_years = list(range(current_year - 3, current_year + 1))

        if_items = []
        for year in if_publication_years:
            from_date = f"{year}-01-01"
            until_date = f"{year}-12-31"
            items = fetch_articles_enhanced(issn, from_date, until_date, use_cache)
            if_items.extend(items)

        cs_items = []
        for year in cs_publication_years:
            from_date = f"{year}-01-01"
            until_date = f"{year}-12-31"
            items = fetch_articles_enhanced(issn, from_date, until_date, use_cache)
            cs_items.extend(items)

        B_if = len(if_items)
        B_cs = len(cs_items)
        if B_if == 0 or B_cs == 0:
            print(f"calculate_metrics_fast: –ù–µ—Ç —Å—Ç–∞—Ç–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: IF={B_if}, CS={B_cs}")
            return None

        A_if_current = sum(item.get('is-referenced-by-count', 0) for item in if_items)
        A_cs_current = sum(item.get('is-referenced-by-count', 0) for item in cs_items)

        current_if = A_if_current / B_if if B_if > 0 else 0
        current_citescore = A_cs_current / B_cs if B_cs > 0 else 0

        seasonal_coefficients = get_seasonal_coefficients(journal_field)
        multiplier = calculate_weighted_multiplier(current_date, seasonal_coefficients, "balanced")
        
        if_forecasts = {
            'conservative': current_if * max(1.0, multiplier * 0.9),
            'balanced': current_if * max(1.0, multiplier),
            'optimistic': current_if * max(1.0, multiplier * 1.1)
        }

        citescore_forecasts = {
            'conservative': current_citescore * max(1.0, multiplier * 0.9),
            'balanced': current_citescore * max(1.0, multiplier),
            'optimistic': current_citescore * max(1.0, multiplier * 1.1)
        }

        if_citation_data = [
            {
                'DOI': item.get('DOI', 'N/A'),
                '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None]])[0][0],
                '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Crossref)': item.get('is-referenced-by-count', 0),
                '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (OpenAlex)': 0,
                '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–∏–æ–¥–µ': 0
            } for item in if_items
        ]

        cs_citation_data = [
            {
                'DOI': item.get('DOI', 'N/A'),
                '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None]])[0][0],
                '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Crossref)': item.get('is-referenced-by-count', 0),
                '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (OpenAlex)': 0,
                '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–∏–æ–¥–µ': 0
            } for item in cs_items
        ]

        return {
            'current_if': current_if,
            'current_citescore': current_citescore,
            'if_forecasts': if_forecasts,
            'citescore_forecasts': citescore_forecasts,
            'multipliers': {
                'conservative': max(1.0, multiplier * 0.9),
                'balanced': max(1.0, multiplier),
                'optimistic': max(1.0, multiplier * 1.1)
            },
            'total_cites_if': A_if_current,
            'total_articles_if': B_if,
            'total_cites_cs': A_cs_current,
            'total_articles_cs': B_cs,
            'citation_distribution': dict(seasonal_coefficients),
            'if_citation_data': if_citation_data,
            'cs_citation_data': cs_citation_data,
            'analysis_date': current_date,
            'if_publication_years': if_publication_years,
            'cs_publication_years': cs_publication_years,
            'seasonal_coefficients': seasonal_coefficients,
            'journal_field': journal_field,
            'self_citation_rate': 0.05,
            'total_self_citations': int(A_if_current * 0.05),
            'issn': issn,
            'journal_name': journal_name,
            'citation_model_data': []
        }

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤ calculate_metrics_fast: {e}")
        return None

def calculate_metrics_enhanced(issn, journal_name="–ù–µ —É–∫–∞–∑–∞–Ω–æ", use_cache=True, progress_callback=None, use_parallel=True, max_workers=20):
    """–£–°–û–í–ï–†–®–ï–ù–°–¢–í–û–í–ê–ù–ù–ê–Ø —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫ —Å OpenAlex –¥–ª—è –ò–§"""
    try:
        print(f"–ó–∞–ø—É—Å–∫ calculate_metrics_enhanced –¥–ª—è ISSN {issn}")
        if not validate_issn(issn):
            print(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç ISSN: {issn}")
            return None

        parallel_ok, effective_workers = validate_parallel_openalex(max_workers)
        if use_parallel and parallel_ok:
            print(f"‚úÖ –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏—è –≤–∫–ª—é—á–µ–Ω–∞: {effective_workers} –ø–æ—Ç–æ–∫–æ–≤")
        else:
            use_parallel = False
            print("‚ö†Ô∏è –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞")

        current_date = date.today()
        current_year = current_date.year
        journal_field = detect_journal_field(issn, journal_name)

        if progress_callback:
            progress_callback(0.0)
            print("–ù–∞—á–∞–ª–æ —Å–±–æ—Ä–∞ —Å—Ç–∞—Ç–µ–π –∏–∑ Crossref...")

        if_publication_years = [current_year - 2, current_year - 1]
        cs_publication_years = list(range(current_year - 3, current_year + 1))

        all_articles = {}
        if_items = []
        for year in if_publication_years:
            from_date = f"{year}-01-01"
            until_date = f"{year}-12-31"
            items = fetch_articles_enhanced(issn, from_date, until_date, use_cache, progress_callback)
            if_items.extend(items)
            all_articles[year] = items
            print(f"–ì–æ–¥ {year}: –ù–∞–π–¥–µ–Ω–æ {len(items)} —Å—Ç–∞—Ç–µ–π")

        cs_items = []
        for year in cs_publication_years:
            if year not in all_articles:
                from_date = f"{year}-01-01"
                until_date = f"{year}-12-31"
                items = fetch_articles_enhanced(issn, from_date, until_date, use_cache, progress_callback)
                all_articles[year] = items
                print(f"–ì–æ–¥ {year}: –ù–∞–π–¥–µ–Ω–æ {len(items)} —Å—Ç–∞—Ç–µ–π")
            cs_items.extend(all_articles[year])

        B_if = len(if_items)
        B_cs = len(cs_items)
        print(f"–°—Ç–∞—Ç—å–∏ –¥–ª—è –ò–§ (2023‚Äì2024): {B_if}")
        print(f"–°—Ç–∞—Ç—å–∏ –¥–ª—è CiteScore (2022‚Äì2025): {B_cs}")
        if B_if == 0 or B_cs == 0:
            print(f"calculate_metrics_enhanced: –ù–µ—Ç —Å—Ç–∞—Ç–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: IF={B_if}, CS={B_cs}")
            if progress_callback:
                progress_callback(1.0)
            return None

        if progress_callback:
            progress_callback(0.3)
            print("–ù–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π —á–µ—Ä–µ–∑ OpenAlex...")

        A_if_current = 0
        valid_dois = 0
        if_citation_data = []
        
        dois_if = [item.get('DOI') for item in if_items if item.get('DOI') != 'N/A']
        
        if use_parallel and dois_if:
            print(f"üöÄ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ {len(dois_if)} DOI –¥–ª—è –ò–§...")
            parallel_results = parallel_fetch_citations_openalex(
                dois_if,
                date(current_year, 1, 1),
                date(current_year, 12, 31),
                effective_workers,
                progress_callback
            )
            
            for item in if_items:
                doi = item.get('DOI', 'N/A')
                crossref_cites = item.get('is-referenced-by-count', 0)
                
                if doi != 'N/A' and doi in parallel_results:
                    result = parallel_results[doi]
                    A_if_current += result['count']
                    valid_dois += 1
                    if_citation_data.append({
                        'DOI': doi,
                        '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None]])[0][0],
                        '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None, None, None]])[0][:3],
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Crossref)': crossref_cites,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (OpenAlex)': result['total_count'],
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–∏–æ–¥–µ': result['count']
                    })
                else:
                    if_citation_data.append({
                        'DOI': doi,
                        '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None]])[0][0],
                        '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None, None, None]])[0][:3],
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Crossref)': crossref_cites,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (OpenAlex)': 0,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–∏–æ–¥–µ': 0
                    })
        else:
            for i, item in enumerate(if_items):
                doi = item.get('DOI', 'N/A')
                crossref_cites = item.get('is-referenced-by-count', 0)
                if doi != 'N/A':
                    result = fetch_citations_openalex(
                        doi,
                        date(current_year, 1, 1),
                        date(current_year, 12, 31),
                        lambda p: progress_callback(0.3 + 0.6 * (i + 1) / B_if * p) if progress_callback else None
                    )
                    A_if_current += result['count']
                    valid_dois += 1
                    if_citation_data.append({
                        'DOI': doi,
                        '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None]])[0][0],
                        '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None, None, None]])[0][:3],
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Crossref)': crossref_cites,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (OpenAlex)': result['total_count'],
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–∏–æ–¥–µ': result['count']
                    })
                else:
                    if_citation_data.append({
                        'DOI': doi,
                        '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None]])[0][0],
                        '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None, None, None]])[0][:3],
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Crossref)': crossref_cites,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (OpenAlex)': 0,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–∏–æ–¥–µ': 0
                    })
        
        print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ DOI: {valid_dois}/{B_if}, –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π –≤ {current_year}: {A_if_current}")

        A_cs_current = sum(item.get('is-referenced-by-count', 0) for item in cs_items)
        cs_citation_data = [
            {
                'DOI': item.get('DOI', 'N/A'),
                '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None]])[0][0],
                '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None, None, None]])[0][:3],
                '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Crossref)': item.get('is-referenced-by-count', 0),
                '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (OpenAlex)': 0,
                '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–∏–æ–¥–µ': 0
            } for item in cs_items
        ]

        current_if = A_if_current / B_if if B_if > 0 else 0
        current_citescore = A_cs_current / B_cs if B_cs > 0 else 0

        if progress_callback:
            progress_callback(0.9)
            print("–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫...")

        seasonal_coefficients = get_seasonal_coefficients(journal_field)
        multiplier_conservative = calculate_weighted_multiplier(current_date, seasonal_coefficients, "conservative")
        multiplier_balanced = calculate_weighted_multiplier(current_date, seasonal_coefficients, "balanced")
        multiplier_optimistic = calculate_weighted_multiplier(current_date, seasonal_coefficients, "optimistic")

        if_forecasts = {
            'conservative': current_if * multiplier_conservative,
            'balanced': current_if * multiplier_balanced,
            'optimistic': current_if * multiplier_optimistic
        }

        citescore_forecasts = {
            'conservative': current_citescore * multiplier_conservative,
            'balanced': current_citescore * multiplier_balanced,
            'optimistic': current_citescore * multiplier_optimistic
        }

        if progress_callback:
            progress_callback(1.0)
            print("–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")

        return {
            'current_if': current_if,
            'current_citescore': current_citescore,
            'if_forecasts': if_forecasts,
            'citescore_forecasts': citescore_forecasts,
            'multipliers': {
                'conservative': multiplier_conservative,
                'balanced': multiplier_balanced,
                'optimistic': multiplier_optimistic
            },
            'total_cites_if': A_if_current,
            'total_articles_if': B_if,
            'total_cites_cs': A_cs_current,
            'total_articles_cs': B_cs,
            'citation_distribution': dict(seasonal_coefficients),
            'if_citation_data': if_citation_data,
            'cs_citation_data': cs_citation_data,
            'analysis_date': current_date,
            'if_publication_years': if_publication_years,
            'cs_publication_years': cs_publication_years,
            'seasonal_coefficients': seasonal_coefficients,
            'journal_field': journal_field,
            'self_citation_rate': 0.05,
            'total_self_citations': int(A_if_current * 0.05),
            'issn': issn,
            'journal_name': journal_name,
            'citation_model_data': [],
            'parallel_processing': use_parallel,
            'parallel_workers': effective_workers
        }

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤ calculate_metrics_enhanced –¥–ª—è ISSN {issn}: {e}")
        if progress_callback:
            progress_callback(1.0)
        return None

def calculate_metrics_dynamic(issn, journal_name="–ù–µ —É–∫–∞–∑–∞–Ω–æ", use_cache=True, progress_callback=None, use_parallel=True, max_workers=20):
    """–î–ò–ù–ê–ú–ò–ß–ï–°–ö–ê–Ø —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ –ø–µ—Ä–∏–æ–¥–∞–º–∏"""
    try:
        print(f"–ó–∞–ø—É—Å–∫ calculate_metrics_dynamic –¥–ª—è ISSN {issn}")
        if not validate_issn(issn):
            print(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç ISSN: {issn}")
            return None

        parallel_ok, effective_workers = validate_parallel_openalex(max_workers)
        if use_parallel and parallel_ok:
            print(f"‚úÖ –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏—è –≤–∫–ª—é—á–µ–Ω–∞: {effective_workers} –ø–æ—Ç–æ–∫–æ–≤")
        else:
            use_parallel = False
            print("‚ö†Ô∏è –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞")

        current_date = date.today()
        journal_field = detect_journal_field(issn, journal_name)

        if progress_callback:
            progress_callback(0.0)
            print("–ù–∞—á–∞–ª–æ —Å–±–æ—Ä–∞ —Å—Ç–∞—Ç–µ–π –∏–∑ Crossref...")

        # –ü–µ—Ä–∏–æ–¥—ã –¥–ª—è –ò–§
        if_citation_start = current_date - timedelta(days=18*30)
        if_citation_end = current_date - timedelta(days=6*30)
        if_article_start = current_date - timedelta(days=42*30)
        if_article_end = current_date - timedelta(days=18*30)

        # –ü–µ—Ä–∏–æ–¥—ã –¥–ª—è CiteScore (2021‚Äì2025 –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —É—á–µ—Ç–∞ —Å—Ç–∞—Ç–µ–π)
        cs_citation_start = current_date - timedelta(days=52*30)
        cs_citation_end = current_date - timedelta(days=4*30)
        cs_article_start = current_date - timedelta(days=52*30)
        cs_article_end = current_date - timedelta(days=4*30)

        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π –¥–ª—è –ò–§
        if_items = fetch_articles_enhanced(
            issn,
            if_article_start.strftime('%Y-%m-%d'),
            if_article_end.strftime('%Y-%m-%d'),
            use_cache,
            progress_callback
        )

        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–µ–π –¥–ª—è CiteScore
        cs_items = fetch_articles_enhanced(
            issn,
            cs_article_start.strftime('%Y-%m-%d'),
            cs_article_end.strftime('%Y-%m-%d'),
            use_cache,
            progress_callback
        )

        B_if = len(if_items)
        B_cs = len(cs_items)
        print(f"–°—Ç–∞—Ç—å–∏ –¥–ª—è –ò–§ ({if_article_start}‚Äì{if_article_end}): {B_if}")
        print(f"–°—Ç–∞—Ç—å–∏ –¥–ª—è CiteScore ({cs_article_start}‚Äì{cs_article_end}): {B_cs}")
        if B_if == 0 or B_cs == 0:
            print(f"calculate_metrics_dynamic: –ù–µ—Ç —Å—Ç–∞—Ç–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: IF={B_if}, CS={B_cs}")
            if progress_callback:
                progress_callback(1.0)
            return None

        if progress_callback:
            progress_callback(0.3)
            print("–ù–∞—á–∞–ª–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π —á–µ—Ä–µ–∑ OpenAlex...")

        # –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–´–ô —Ä–∞—Å—á–µ—Ç –ò–§
        A_if_current = 0
        valid_dois_if = 0
        if_citation_data = []
        
        dois_if = [item.get('DOI') for item in if_items if item.get('DOI') != 'N/A']
        
        if use_parallel and dois_if:
            print(f"üöÄ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ {len(dois_if)} DOI –¥–ª—è –ò–§...")
            parallel_results_if = parallel_fetch_citations_openalex(
                dois_if,
                if_citation_start,
                if_citation_end,
                effective_workers,
                lambda p: progress_callback(0.3 + 0.3 * p)
            )
            
            for item in if_items:
                doi = item.get('DOI', 'N/A')
                crossref_cites = item.get('is-referenced-by-count', 0)
                pub_date_parts = item.get('published', {}).get('date-parts', [[None, None, None]])[0]
                pub_date = f"{pub_date_parts[0] or 'N/A'}-{pub_date_parts[1] or 1:02d}-{pub_date_parts[2] or 1:02d}"
                
                if doi != 'N/A' and doi in parallel_results_if:
                    result = parallel_results_if[doi]
                    A_if_current += result['count']
                    valid_dois_if += 1
                    if_citation_data.append({
                        'DOI': doi,
                        '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None]])[0][0],
                        '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': pub_date,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Crossref)': crossref_cites,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (OpenAlex)': result['total_count'],
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–∏–æ–¥–µ': result['count']
                    })
                else:
                    if_citation_data.append({
                        'DOI': doi,
                        '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None]])[0][0],
                        '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': pub_date,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Crossref)': crossref_cites,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (OpenAlex)': 0,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–∏–æ–¥–µ': 0
                    })
        else:
            for i, item in enumerate(if_items):
                doi = item.get('DOI', 'N/A')
                crossref_cites = item.get('is-referenced-by-count', 0)
                pub_date_parts = item.get('published', {}).get('date-parts', [[None, None, None]])[0]
                pub_date = f"{pub_date_parts[0] or 'N/A'}-{pub_date_parts[1] or 1:02d}-{pub_date_parts[2] or 1:02d}"
                
                if doi != 'N/A':
                    result = fetch_citations_openalex(
                        doi,
                        if_citation_start,
                        if_citation_end,
                        lambda p: progress_callback(0.3 + 0.3 * (i + 1) / B_if * p) if progress_callback else None
                    )
                    A_if_current += result['count']
                    valid_dois_if += 1
                    if_citation_data.append({
                        'DOI': doi,
                        '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None]])[0][0],
                        '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': pub_date,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Crossref)': crossref_cites,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (OpenAlex)': result['total_count'],
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–∏–æ–¥–µ': result['count']
                    })
                else:
                    if_citation_data.append({
                        'DOI': doi,
                        '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None]])[0][0],
                        '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': pub_date,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Crossref)': crossref_cites,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (OpenAlex)': 0,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–∏–æ–¥–µ': 0
                    })
        
        print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ DOI –¥–ª—è –ò–§: {valid_dois_if}/{B_if}")

        # –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–´–ô —Ä–∞—Å—á–µ—Ç CiteScore (OpenAlex –∏ Crossref)
        A_cs_current_openalex = 0
        A_cs_current_crossref = sum(item.get('is-referenced-by-count', 0) for item in cs_items)
        valid_dois_cs = 0
        cs_citation_data = []
        
        dois_cs = [item.get('DOI') for item in cs_items if item.get('DOI') != 'N/A']
        
        if use_parallel and dois_cs:
            print(f"üöÄ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ {len(dois_cs)} DOI –¥–ª—è CiteScore...")
            parallel_results_cs = parallel_fetch_citations_openalex(
                dois_cs,
                cs_citation_start,
                cs_citation_end,
                effective_workers,
                lambda p: progress_callback(0.6 + 0.3 * p)
            )
            
            for item in cs_items:
                doi = item.get('DOI', 'N/A')
                crossref_cites = item.get('is-referenced-by-count', 0)
                pub_date_parts = item.get('published', {}).get('date-parts', [[None, None, None]])[0]
                pub_date = f"{pub_date_parts[0] or 'N/A'}-{pub_date_parts[1] or 1:02d}-{pub_date_parts[2] or 1:02d}"
                
                if doi != 'N/A' and doi in parallel_results_cs:
                    result = parallel_results_cs[doi]
                    A_cs_current_openalex += result['count']
                    valid_dois_cs += 1
                    cs_citation_data.append({
                        'DOI': doi,
                        '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None]])[0][0],
                        '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': pub_date,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Crossref)': crossref_cites,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (OpenAlex)': result['total_count'],
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–∏–æ–¥–µ': result['count']
                    })
                else:
                    cs_citation_data.append({
                        'DOI': doi,
                        '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None]])[0][0],
                        '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': pub_date,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Crossref)': crossref_cites,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (OpenAlex)': 0,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–∏–æ–¥–µ': 0
                    })
        else:
            for i, item in enumerate(cs_items):
                doi = item.get('DOI', 'N/A')
                crossref_cites = item.get('is-referenced-by-count', 0)
                pub_date_parts = item.get('published', {}).get('date-parts', [[None, None, None]])[0]
                pub_date = f"{pub_date_parts[0] or 'N/A'}-{pub_date_parts[1] or 1:02d}-{pub_date_parts[2] or 1:02d}"
                
                if doi != 'N/A':
                    result = fetch_citations_openalex(
                        doi,
                        cs_citation_start,
                        cs_citation_end,
                        lambda p: progress_callback(0.6 + 0.3 * (i + 1) / B_cs * p) if progress_callback else None
                    )
                    A_cs_current_openalex += result['count']
                    valid_dois_cs += 1
                    cs_citation_data.append({
                        'DOI': doi,
                        '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None]])[0][0],
                        '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': pub_date,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Crossref)': crossref_cites,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (OpenAlex)': result['total_count'],
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–∏–æ–¥–µ': result['count']
                    })
                else:
                    cs_citation_data.append({
                        'DOI': doi,
                        '–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': item.get('published', {}).get('date-parts', [[None]])[0][0],
                        '–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏': pub_date,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (Crossref)': crossref_cites,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (OpenAlex)': 0,
                        '–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø–µ—Ä–∏–æ–¥–µ': 0
                    })
        
        print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ DOI –¥–ª—è CiteScore: {valid_dois_cs}/{B_cs}")

        current_if = A_if_current / B_if if B_if > 0 else 0
        current_citescore_openalex = A_cs_current_openalex / B_cs if B_cs > 0 else 0
        current_citescore_crossref = A_cs_current_crossref / B_cs if B_cs > 0 else 0

        if progress_callback:
            progress_callback(0.9)
            print("–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫...")

        seasonal_coefficients = get_seasonal_coefficients(journal_field)

        if progress_callback:
            progress_callback(1.0)
            print("–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω")

        return {
            'current_if': current_if,
            'current_citescore_openalex': current_citescore_openalex,
            'current_citescore_crossref': current_citescore_crossref,
            'total_cites_if': A_if_current,
            'total_articles_if': B_if,
            'total_cites_cs_openalex': A_cs_current_openalex,
            'total_cites_cs_crossref': A_cs_current_crossref,
            'total_articles_cs': B_cs,
            'citation_distribution': dict(seasonal_coefficients),
            'if_citation_data': if_citation_data,
            'cs_citation_data': cs_citation_data,
            'analysis_date': current_date,
            'if_publication_period': [if_article_start, if_article_end],
            'if_citation_period': [if_citation_start, if_citation_end],
            'cs_publication_period': [cs_article_start, cs_article_end],
            'cs_citation_period': [cs_citation_start, cs_citation_end],
            'seasonal_coefficients': seasonal_coefficients,
            'journal_field': journal_field,
            'self_citation_rate': 0.05,
            'total_self_citations': int(A_if_current * 0.05),
            'issn': issn,
            'journal_name': journal_name,
            'citation_model_data': [],
            'parallel_processing': use_parallel,
            'parallel_workers': effective_workers
        }

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤ calculate_metrics_dynamic –¥–ª—è ISSN {issn}: {e}")
        if progress_callback:
            progress_callback(1.0)
        return None

def on_clear_cache_clicked(b):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∫—ç—à–∞"""
    try:
        if os.path.exists(CACHE_DIR):
            for file in os.listdir(CACHE_DIR):
                file_path = os.path.join(CACHE_DIR, file)
                try:
                    if os.path.isfile(file_path):
                        os.unlink(file_path)
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ {file_path}: {e}")
            print("–ö—ç—à —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω")
            return "–ö—ç—à —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω!"
        else:
            print("–ö—ç—à —É–∂–µ –ø—É—Å—Ç")
            return "–ö—ç—à —É–∂–µ –ø—É—Å—Ç"
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –∫—ç—à–∞: {e}")
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –∫—ç—à–∞: {e}"



