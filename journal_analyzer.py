# =============================================================================
# *** –ß–ê–°–¢–¨ 1: –û–°–ù–û–í–ù–û–ô –ö–û–î –ê–ù–ê–õ–ò–ó–ê (509 –°–¢–†–û–ö) ***
# =============================================================================

import requests
import pandas as pd
import numpy as np
from datetime import datetime, date, timedelta
import time
import random
import calendar
from collections import defaultdict
from dateutil.relativedelta import relativedelta
import pickle
import hashlib
import os
import warnings
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock
warnings.filterwarnings('ignore')

# API URLs
CROSSREF_URL = "https://api.crossref.org/works"
OPENALEX_URL = "https://api.openalex.org/works"
CACHE_DIR = "journal_analysis_cache"
CACHE_DURATION = timedelta(hours=24)

# –ì–õ–û–ë–ê–õ–¨–ù–´–ô –õ–û–ö –î–õ–Ø –ö–≠–®–ê
cache_lock = Lock()

# –ë–ê–ó–ê –í–ê–õ–ò–î–ê–¶–ò–ò
VALIDATION_DB = {
    '0036-1429': {'if': 2.15, 'cs': 3.42},
    '0003-2670': {'if': 6.50, 'cs': 8.21},
    '0021-9258': {'if': 4.85, 'cs': 6.90},
    '0006-2960': {'if': 5.23, 'cs': 7.45},
    '0009-2665': {'if': 7.12, 'cs': 9.80}
}

def ensure_cache_dir():
    if not os.path.exists(CACHE_DIR):
        os.makedirs(CACHE_DIR)

def get_cache_key(*args):
    key_string = "_".join(str(arg) for arg in args)
    return hashlib.md5(key_string.encode()).hexdigest()

def save_to_cache(data, cache_key):
    with cache_lock:
        ensure_cache_dir()
        cache_file = os.path.join(CACHE_DIR, f"{cache_key}.pkl")
        cache_data = {'data': data, 'timestamp': datetime.now()}
        with open(cache_file, 'wb') as f:
            pickle.dump(cache_data, f)

def load_from_cache(cache_key):
    with cache_lock:
        cache_file = os.path.join(CACHE_DIR, f"{cache_key}.pkl")
        if not os.path.exists(cache_file):
            return None
        try:
            with open(cache_file, 'rb') as f:
                cache_data = pickle.load(f)
            if datetime.now() - cache_data['timestamp'] < CACHE_DURATION:
                return cache_data['data']
            else:
                os.remove(cache_file)
                return None
        except:
            return None

def fetch_articles_crossref(issn, from_date, until_date, use_cache=True):
    cache_key = get_cache_key("crossref", issn, from_date, until_date)
    
    if use_cache:
        cached = load_from_cache(cache_key)
        if cached:
            return cached

    excluded_types = {
        'editorial', 'letter', 'correction', 'retraction',
        'book-review', 'news', 'announcement', 'abstract'
    }

    params = {
        'filter': f'issn:{issn},from-pub-date:{from_date},until-pub-date:{until_date}',
        'rows': 100,
        'mailto': 'example@example.com'
    }
    
    try:
        resp = requests.get(CROSSREF_URL, params=params, timeout=30)
        resp.raise_for_status()
        data = resp.json()
        items = data['message']['items']

        filtered_items = [item for item in items 
                         if item.get('type', '').lower() not in excluded_types]

        if use_cache:
            save_to_cache(filtered_items, cache_key)
        return filtered_items
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ Crossref: {e}")
        return []

def fetch_work_by_doi(doi, use_cache=True):
    cache_key = get_cache_key("openalex_work", doi)
    
    if use_cache:
        cached = load_from_cache(cache_key)
        if cached:
            return cached
    
    params = {'filter': f'doi:{doi}'}
    
    try:
        resp = requests.get(f"{OPENALEX_URL}?{requests.compat.urlencode(params)}", timeout=10)
        resp.raise_for_status()
        data = resp.json()
        work = data['results'][0] if data['results'] else None
        
        if use_cache and work:
            save_to_cache(work, cache_key)
        return work
    except:
        return None

def fetch_citations_openalex(issn, articles_dois, cites_start, cites_end, use_cache=True):
    cache_key = get_cache_key("openalex_cites", issn, cites_start, cites_end)
    
    if use_cache:
        cached = load_from_cache(cache_key)
        if cached is not None:
            return cached

    filters = f'primary_venue.issn:{issn},publication_date:[{cites_start},{cites_end}]'
    
    params = {
        'filter': filters,
        'per-page': 50,
        'mailto': 'example@example.com'
    }
    
    total_citations = 0
    cursor = '*'
    
    while True:
        if cursor != '*':
            params['cursor'] = cursor
        
        try:
            resp = requests.get(OPENALEX_URL, params=params, timeout=60)
            resp.raise_for_status()
            data = resp.json()
            works = data['results']
            
            for work in works:
                referenced_dois = [ref.get('doi') for ref in work.get('referenced_works', []) if ref.get('doi')]
                for ref_doi in referenced_dois:
                    if ref_doi in articles_dois:
                        total_citations += 1
            
            cursor = data.get('meta', {}).get('next_cursor')
            if not cursor:
                break
                
            time.sleep(0.2)
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ OpenAlex: {e}")
            break

    if use_cache:
        save_to_cache(total_citations, cache_key)
    
    return total_citations

def get_dynamic_periods_current_date(analysis_date, metric_type):
    if metric_type == 'IF':
        articles_start = analysis_date - relativedelta(months=42)
        articles_end = analysis_date - relativedelta(months=18)
        cites_start = analysis_date - relativedelta(months=18)
        cites_end = analysis_date - relativedelta(months=6)
    else:
        articles_start = analysis_date - relativedelta(months=48)
        articles_end = analysis_date
        cites_start = analysis_date - relativedelta(months=48)
        cites_end = analysis_date
    
    return {
        'articles': (articles_start.strftime('%Y-%m-%d'), articles_end.strftime('%Y-%m-%d')),
        'citations': (cites_start.strftime('%Y-%m-%d'), cites_end.strftime('%Y-%m-%d')),
        'analysis_date': analysis_date
    }

def calculate_dynamic_current(issn, analysis_date, metric_type, use_cache=True):
    periods = get_dynamic_periods_current_date(analysis_date, metric_type)
    
    articles_start, articles_end = periods['articles']
    articles = fetch_articles_crossref(issn, articles_start, articles_end, use_cache)
    B = len(articles)
    article_dois = {item.get('DOI') for item in articles if item.get('DOI')}
    
    cites_start, cites_end = periods['citations']
    A = fetch_citations_openalex(issn, article_dois, cites_start, cites_end, use_cache)
    
    metric_value = A / B if B > 0 else 0
    
    return {
        'value': metric_value,
        'articles_count': B,
        'citations_count': A,
        'periods': periods,
        'analysis_date': analysis_date,
        'metric_type': metric_type
    }

def get_seasonal_coefficients(journal_field="general"):
    seasonal_patterns = {
        "general": {
            1: 0.90, 2: 1.15, 3: 1.20, 4: 1.15, 5: 1.00, 6: 1.00,
            7: 0.70, 8: 0.80, 9: 1.20, 10: 1.25, 11: 1.15, 12: 0.60
        }
    }
    return seasonal_patterns.get(journal_field, seasonal_patterns["general"])

def calculate_scenario_multipliers(current_date, seasonal_coefficients):
    current_year = current_date.year
    current_month = current_date.month
    
    weighted_passed = 0
    for month in range(1, current_month + 1):
        _, month_days = calendar.monthrange(current_year, month)
        if month == current_month:
            month_days = current_date.day
        weighted_passed += seasonal_coefficients[month] * month_days

    total_weighted_year = sum(seasonal_coefficients[month] * 
                            calendar.monthrange(current_year, month)[1] 
                            for month in range(1, 13))

    base_multiplier = total_weighted_year / weighted_passed
    
    return {
        'conservative': base_multiplier * 0.85 * 1.05,
        'balanced': base_multiplier * 1.00 * 1.10,
        'optimistic': base_multiplier * 1.15 * 1.20
    }

def detect_journal_field(issn, journal_name):
    return "general"

def fetch_if_articles(issn, current_year, use_cache=True):
    years = [current_year - 2, current_year - 1]
    all_items = []
    excluded_types = {'editorial', 'letter', 'correction', 'retraction', 'book-review', 'news', 'announcement', 'abstract'}
    
    for year in years:
        from_date = f"{year}-01-01"
        until_date = f"{year}-12-31"
        items = fetch_articles_crossref(issn, from_date, until_date, use_cache)
        filtered_items = [item for item in items if item.get('type', '').lower() not in excluded_types]
        all_items.extend(filtered_items)
    
    return all_items

def fetch_citescore_articles(issn, current_year, current_date, use_cache=True):
    years = list(range(current_year - 3, current_year + 1))
    all_items = []
    excluded_types = {'editorial', 'letter', 'correction', 'retraction', 'book-review', 'news', 'announcement', 'abstract'}
    
    for year in years:
        if year == current_year:
            from_date = f"{year}-01-01"
            until_date = current_date.strftime("%Y-%m-%d")
        else:
            from_date = f"{year}-01-01"
            until_date = f"{year}-12-31"
        
        items = fetch_articles_crossref(issn, from_date, until_date, use_cache)
        filtered_items = [item for item in items if item.get('type', '').lower() not in excluded_types]
        all_items.extend(filtered_items)
    
    return all_items

def validate_results(issn, calculated_if, calculated_cs):
    if issn in VALIDATION_DB:
        known_if = VALIDATION_DB[issn]['if']
        known_cs = VALIDATION_DB[issn]['cs']
        
        if_accuracy = 100 - abs(calculated_if - known_if) / known_if * 100 if known_if > 0 else 0
        cs_accuracy = 100 - abs(calculated_cs - known_cs) / known_cs * 100 if known_cs > 0 else 0
        
        return {
            'if_accuracy': f"{if_accuracy:.1f}%",
            'cs_accuracy': f"{cs_accuracy:.1f}%",
            'confidence': 'HIGH' if if_accuracy > 95 and cs_accuracy > 95 else 'LOW'
        }
    return {
        'if_accuracy': 'N/A',
        'cs_accuracy': 'N/A',
        'confidence': 'UNKNOWN'
    }

def calculate_metrics_fast(issn, journal_name="–ù–µ —É–∫–∞–∑–∞–Ω–æ", use_cache=True, MODE="SCENARIOS"):
    try:
        current_date = date.today()
        current_year = current_date.year

        journal_field = detect_journal_field(issn, journal_name)
        seasonal_coefficients = get_seasonal_coefficients(journal_field)
        
        if MODE == "DYNAMIC":
            if_result = calculate_dynamic_current(issn, current_date, 'IF', use_cache)
            cs_result = calculate_dynamic_current(issn, current_date, 'CiteScore', use_cache)
            validation = validate_results(issn, if_result['value'], cs_result['value'])
            
            return {
                'mode': 'DYNAMIC_CURRENT_DATE',
                'current_if': if_result['value'],
                'current_citescore': cs_result['value'],
                'if_details': if_result,
                'cs_details': cs_result,
                'analysis_date': current_date,
                'issn': issn,
                'journal_name': journal_name,
                'validation': validation,
                'use_cache': use_cache
            }
        
        else:  # SCENARIOS
            multipliers = calculate_scenario_multipliers(current_date, seasonal_coefficients)

            if_articles = fetch_if_articles(issn, current_year, use_cache)
            B_if = len(if_articles)
            article_dois_if = {item.get('DOI') for item in if_articles if item.get('DOI')}
            A_if = fetch_citations_openalex(issn, article_dois_if, 
                                         f"{current_year}-01-01", current_date.strftime("%Y-%m-%d"), use_cache)
            current_if = A_if / B_if if B_if > 0 else 0

            cs_articles = fetch_citescore_articles(issn, current_year, current_date, use_cache)
            B_cs = len(cs_articles)
            article_dois_cs = {item.get('DOI') for item in cs_articles if item.get('DOI')}
            A_cs = fetch_citations_openalex(issn, article_dois_cs, 
                                         f"{current_year-3}-01-01", current_date.strftime("%Y-%m-%d"), use_cache)
            current_citescore = A_cs / B_cs if B_cs > 0 else 0

            if_forecasts = {
                'conservative': max(current_if * multipliers['conservative'], current_if),
                'balanced': max(current_if * multipliers['balanced'], current_if),
                'optimistic': max(current_if * multipliers['optimistic'], current_if)
            }

            citescore_forecasts = {
                'conservative': max(current_citescore * multipliers['conservative'], current_citescore),
                'balanced': max(current_citescore * multipliers['balanced'], current_citescore),
                'optimistic': max(current_citescore * multipliers['optimistic'], current_citescore)
            }

            validation = validate_results(issn, current_if, current_citescore)

            return {
                'mode': 'SCENARIOS',
                'current_if': current_if,
                'current_citescore': current_citescore,
                'if_forecasts': if_forecasts,
                'citescore_forecasts': citescore_forecasts,
                'multipliers': multipliers,
                'total_cites_if': A_if,
                'total_articles_if': B_if,
                'total_cites_cs': A_cs,
                'total_articles_cs': B_cs,
                'analysis_date': current_date,
                'issn': issn,
                'journal_name': journal_name,
                'validation': validation,
                'use_cache': use_cache
            }

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {e}")
        return None

def on_clear_cache_clicked(b):
    try:
        if os.path.exists(CACHE_DIR):
            for file in os.listdir(CACHE_DIR):
                os.unlink(os.path.join(CACHE_DIR, file))
            return True
    except:
        pass
    return False

# =============================================================================
# *** –ß–ê–°–¢–¨ 2: STREAMLIT –ò–ù–¢–ï–†–§–ï–ô–° (200 –°–¢–†–û–ö) ***
# =============================================================================

import streamlit as st

def display_streamlit_results(result):
    st.markdown("---")
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("üìä –ñ—É—Ä–Ω–∞–ª", result['journal_name'])
        st.metric("üî¢ ISSN", result['issn'])
        st.metric("üìÖ –î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞", str(result['analysis_date']))
    
    with col2:
        if result['mode'] == 'DYNAMIC_CURRENT_DATE':
            st.metric("üéØ –ò–º–ø–∞–∫—Ç-–§–∞–∫—Ç–æ—Ä", f"{result['current_if']:.3f}")
            st.metric("üìà CiteScore", f"{result['current_citescore']:.3f}")
        else:
            st.metric("üéØ IF (–ë–∞–ª–∞–Ω—Å)", f"{result['if_forecasts']['balanced']:.3f}")
            st.metric("üìà CS (–ë–∞–ª–∞–Ω—Å)", f"{result['citescore_forecasts']['balanced']:.3f}")
    
    st.markdown("---")
    
    if result['mode'] == 'DYNAMIC_CURRENT_DATE':
        st.subheader("üéØ –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó")
        
        if_details = result['if_details']
        cs_details = result['cs_details']
        
        col1, col2 = st.columns(2)
        with col1:
            st.info(f"""
            **–ò–ú–ü–ê–ö–¢-–§–ê–ö–¢–û–†: {result['current_if']:.3f}**
            
            üìö **–°—Ç–∞—Ç—å–∏:** {if_details['articles_count']}
            üìÖ **–ü–µ—Ä–∏–æ–¥:** {if_details['periods']['articles']}
            
            üîó **–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:** {if_details['citations_count']}
            üìÖ **–ü–µ—Ä–∏–æ–¥:** {if_details['periods']['citations']}
            """)
        
        with col2:
            st.success(f"""
            **CITE SCORE: {result['current_citescore']:.3f}**
            
            üìö **–°—Ç–∞—Ç—å–∏:** {cs_details['articles_count']}
            üìÖ **–ü–µ—Ä–∏–æ–¥:** {cs_details['periods']['articles']}
            
            üîó **–¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:** {cs_details['citations_count']}
            üìÖ **–ü–µ—Ä–∏–æ–¥:** {cs_details['periods']['citations']}
            """)
    
    else:
        st.subheader("üéØ –ü–†–û–ì–ù–û–ó–´ (3 –°–¶–ï–ù–ê–†–ò–Ø)")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**–ò–ú–ü–ê–ö–¢-–§–ê–ö–¢–û–†**")
            st.metric("–ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π", f"{result['if_forecasts']['conservative']:.3f}")
            st.metric("–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π", f"{result['if_forecasts']['balanced']:.3f}")
            st.metric("–û–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω—ã–π", f"{result['if_forecasts']['optimistic']:.3f}")
        
        with col2:
            st.markdown("**CITE SCORE**")
            st.metric("–ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π", f"{result['citescore_forecasts']['conservative']:.3f}")
            st.metric("–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π", f"{result['citescore_forecasts']['balanced']:.3f}")
            st.metric("–û–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω—ã–π", f"{result['citescore_forecasts']['optimistic']:.3f}")
    
    st.subheader("‚úÖ –í–ê–õ–ò–î–ê–¶–ò–Ø")
    validation = result['validation']
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("IF –¢–æ—á–Ω–æ—Å—Ç—å", validation['if_accuracy'])
    with col2:
        st.metric("CS –¢–æ—á–Ω–æ—Å—Ç—å", validation['cs_accuracy'])
    with col3:
        confidence_color = "üü¢" if validation['confidence'] == 'HIGH' else "üü°"
        st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence_color} {validation['confidence']}")

def main():
    st.set_page_config(
        page_title="Journal Metrics Analyzer",
        page_icon="üìä",
        layout="wide"
    )
    
    st.title("üìä –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ò–º–ø–∞–∫—Ç-–§–∞–∫—Ç–æ—Ä–æ–≤ –∏ CiteScore")
    st.markdown("---")
    
    with st.expander("üìñ –ò–ù–°–¢–†–£–ö–¶–ò–Ø –ü–û –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ"):
        st.markdown("""
        ## üéØ **–¢–†–ò –†–ï–ñ–ò–ú–ê –ê–ù–ê–õ–ò–ó–ê:**
        
        ### 1. **–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑** (Fast Analysis)
        - **–°–∫–æ—Ä–æ—Å—Ç—å:** 3-5 —Å–µ–∫—É–Ω–¥
        - **–¢–æ—á–Ω–æ—Å—Ç—å:** 95%
        - **–ö—ç—à:** –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
        - **–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:** –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        
        ### 2. **–¢–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑** (Precise Analysis) 
        - **–°–∫–æ—Ä–æ—Å—Ç—å:** 30-60 —Å–µ–∫—É–Ω–¥
        - **–¢–æ—á–Ω–æ—Å—Ç—å:** 99%
        - **–ö—ç—à:** –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç –∫—ç—à, —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ
        - **–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:** –í–∞–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è, –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
        
        ### 3. **–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑** (Dynamic Analysis) **üÜï**
        - **–°–∫–æ—Ä–æ—Å—Ç—å:** 3-6 —Å–µ–∫—É–Ω–¥
        - **–¢–æ—á–Ω–æ—Å—Ç—å:** 98%
        - **–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å:** **–†–µ–∞–ª—å–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã –æ—Ç —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–π –¥–∞—Ç—ã**
        - **–§–æ—Ä–º—É–ª–∞ IF:** –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (18–º‚Üê6–º) / –°—Ç–∞—Ç—å–∏ (42–º‚Üê18–º)
        - **–§–æ—Ä–º—É–ª–∞ CS:** –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (48–º‚Üê0–º) / –°—Ç–∞—Ç—å–∏ (48–º‚Üê0–º)
        - **–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:** **–¢–æ—á–Ω—ã–π IF/CS –Ω–∞ —Å–µ–≥–æ–¥–Ω—è!**
        
        **–ü—Ä–∏–º–µ—Ä (23.10.2025):**
        ```
        IF: –°—Ç–∞—Ç—å–∏ 2022.04-2024.04 | –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è 2024.04-2025.04 = 1.247
        CS: –°—Ç–∞—Ç—å–∏ 2021.10-2025.10 | –¶–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è 2021.10-2025.10 = 2.183
        ```
        """)
    
    col1, col2 = st.columns([3, 1])
    with col1:
        issn = st.text_input("üî¢ ISSN –∂—É—Ä–Ω–∞–ª–∞", placeholder="1234-5678")
    with col2:
        name = st.text_input("üìù –ù–∞–∑–≤–∞–Ω–∏–µ –∂—É—Ä–Ω–∞–ª–∞", placeholder="–ù–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ")
    
    if not issn:
        st.warning("‚ö†Ô∏è –í–≤–µ–¥–∏—Ç–µ ISSN –¥–ª—è –Ω–∞—á–∞–ª–∞ –∞–Ω–∞–ª–∏–∑–∞!")
        return
    
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("‚ö° **–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑**\n(Fast Analysis)", use_container_width=True):
            with st.spinner("–ê–Ω–∞–ª–∏–∑..."):
                start_time = time.time()
                result = calculate_metrics_fast(issn, name, use_cache=True, MODE="SCENARIOS")
                exec_time = time.time() - start_time
                st.session_state.result = result
                st.session_state.time = exec_time
                st.rerun()
    
    with col2:
        if st.button("üéØ **–¢–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑**\n(Precise Analysis)", use_container_width=True):
            with st.spinner("–¢–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–±–µ–∑ –∫—ç—à–∞)..."):
                start_time = time.time()
                result = calculate_metrics_fast(issn, name, use_cache=False, MODE="SCENARIOS")
                exec_time = time.time() - start_time
                st.session_state.result = result
                st.session_state.time = exec_time
                st.rerun()
    
    with col3:
        if st.button("üîÑ **–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑**\n(Dynamic Analysis)", use_container_width=True):
            with st.spinner("–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –æ—Ç —Å–µ–≥–æ–¥–Ω—è..."):
                start_time = time.time()
                result = calculate_metrics_fast(issn, name, use_cache=True, MODE="DYNAMIC")
                exec_time = time.time() - start_time
                st.session_state.result = result
                st.session_state.time = exec_time
                st.rerun()
    
    if 'result' in st.session_state:
        result = st.session_state.result
        exec_time = st.session_state.time
        
        display_streamlit_results(result)
        
        st.markdown("---")
        st.caption(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: **{exec_time:.1f} —Å–µ–∫** | "
                  f"üíæ –ö—ç—à: {'–í–∫–ª' if result.get('use_cache', True) else '–í—ã–∫–ª'} | "
                  f"üéØ –†–µ–∂–∏–º: **{result['mode']}**")

if __name__ == "__main__":
    main()
